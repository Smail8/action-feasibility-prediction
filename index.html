<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments - Smail Ait Bouhsain">
  <meta name="description" content="We propose an efficient method for 3D scene representation, along with a deep neural network capable of predicting the probability of feasibility of an action in task and motion planning. We demonstrate the performance gain of using our approach on multiple problem domains, significantly reducing geometric planning time.">
  <meta name="keywords" content="task and motion planning, TAMP, 3D environments, action feasibility prediction, deep neural networks, robotics, scene representation, manipulation planning, geometric planning, machine learning, artificial intelligence">
  <meta name="author" content="Smail Ait Bouhsain, Rachid Alami, Thierry Siméon">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="LAAS-CNRS">
  <meta property="og:title" content="Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments">
  <meta property="og:description" content="We propose an efficient method for 3D scene representation, along with a deep neural network capable of predicting the probability of feasibility of an action in task and motion planning. We demonstrate the performance gain of using our approach on multiple problem domains, significantly reducing geometric planning time.">
  <meta property="og:url" content="https://smail8.github.io/action-feasibility-prediction/">
  <meta property="og:image" content="https://github.com/Smail8/action-feasibility-prediction/tree/master/static/images/poster.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments - Research Preview">
  <meta property="article:published_time" content="2023-05-29T00:00:00.000Z">
  <meta property="article:author" content="Smail Ait Bouhsain">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="task and motion planning">
  <meta property="article:tag" content="action feasibility prediction">
  <meta property="article:tag" content="robotics">
  <meta property="article:tag" content="deep learning">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@LaasCNRS">
  <meta name="twitter:creator" content="@Sm1Le8B">
  <meta name="twitter:title" content="Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments">
  <meta name="twitter:description" content="We propose an efficient method for 3D scene representation, along with a deep neural network capable of predicting the probability of feasibility of an action in task and motion planning. We demonstrate the performance gain of using our approach on multiple problem domains, significantly reducing geometric planning time.">
  <meta name="twitter:image" content="https://github.com/Smail8/action-feasibility-prediction/tree/master/static/images/poster.png">
  <meta name="twitter:image:alt" content="Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments">
  <meta name="citation_author" content="Ait Bouhsain, Smail">
  <meta name="citation_author" content="Alami, Rachid">
  <meta name="citation_author" content="Siméon, Thierry">
  <meta name="citation_publication_date" content="2023">
  <meta name="citation_conference_title" content="IEEE International Conference on Robotics and Automation (ICRA)">
  <meta name="citation_pdf_url" content="https://github.com/Smail8/action-feasibility-prediction/tree/master/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments - Ait Bouhsain, Smail, Alami, Rachid, Siméon, Thierry | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/panda_icon.png">
  <link rel="apple-touch-icon" href="static/images/panda_icon.png">

  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments",
    "description": "This paper presents a novel approach to predicting action feasibility in 3D environments, significantly improving task and motion planning.",
    "author": [
      {
        "@type": "Person",
        "name": "Smail Ait Bouhsain",
        "affiliation": {
          "@type": "Organization",
          "name": "LAAS-CNRS"
        }
      },
      {
        "@type": "Person",
        "name": "Rachid Alami",
        "affiliation": {
          "@type": "Organization",
          "name": "LAAS-CNRS"
        }
      },
      {
        "@type": "Person",
        "name": "Thierry Siméon",
        "affiliation": {
          "@type": "Organization",
          "name": "LAAS-CNRS"
        }
      }
    ],
    "datePublished": "2023-05-29",
    "publisher": {
      "@type": "Organization",
      "name": "IEEE International Conference on Robotics and Automation (ICRA)"
    },
    "url": "https://smail8.github.io/action-feasibility-prediction/",
    "image": "https://github.com/Smail8/action-feasibility-prediction/tree/master/static/images/poster.png",
    "keywords": [
      "task and motion planning",
      "TAMP",
      "3D environments",
      "action feasibility prediction",
      "deep neural networks",
      "robotics",
      "scene representation",
      "manipulation planning",
      "geometric planning",
      "machine learning",
      "artificial intelligence"
    ],
    "abstract": 
    "In Task and motion planning (TAMP), symbolic search is combined with continuous geometric planning. A task planner finds an action sequence while a motion planner checks its feasibility and plans the corresponding sequence of motions. However, due to the high combinatorial complexity of discrete search, the number of calls to the geometric planner can be very large. Previous works [1] [2] leverage learning methods to efficiently predict the feasibility of actions, much like humans do, on tabletop scenarios. This way, the time spent on motion planning can be greatly reduced. In this work, we generalize these methods to 3D environments, thus covering the whole workspace of the robot. We propose an efficient method for 3D scene representation, along with a deep neural network capable of predicting the probability of feasibility of an action. We develop a simple TAMP algorithm that integrates the trained classifier, and demonstrate the performance gain of using our approach on multiple problem domains. On complex problems, our method can reduce the time spent on geometric planning by up to 90%.",
    "citation": 
    "@inproceedings{ait2023learning,
      title={Learning to predict action feasibility for task and motion planning in 3d environments},
      author={Ait Bouhsain, Smail and Alami, Rachid and Simeon, Thierry},
      booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
      pages={3736--3742},
      year={2023},
      organization={IEEE}
    }",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://smail8.github.io/action-feasibility-prediction/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "AI for Robotics"
      },
      {
        "@type": "Thing", 
        "name": "Machine Learning"
      },
      {
        "@type": "Thing", 
        "name": "Task and Motion Planning"
      },
      {
        "@type": "Thing", 
        "name": "Deep Learning"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "LAAS-CNRS",
    "url": "https://www.laas.fr",
    "logo": "https://github.com/Smail8/action-feasibility-prediction/tree/master/static/images/laas_logo.png",
    "sameAs": [
      "https://twitter.com/LaasCNRS",
      "https://github.com/Smail8"
    ]
  }
  </script>
</head>

<body>
  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <a href="https://openreview.net/pdf?id=ajxAJ8GUX4" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Learning Geometric Reasoning Networks for Robot Task and Motion Planning</h5>
            <p>We present Geometric Reasoning Networks (GRN), a graph neural network-based model for predicting action and grasp feasibility in Task and Motion Planning (TAMP). GRN reduces reliance on geometric planners by incorporating interpretability mechanisms such as inverse kinematics feasibility prediction and grasp obstruction estimation, enabling efficient and explainable planning in complex 3D environments.</p>
            <span class="work-venue">The Thirteenth International Conference on Learning Representations (ICLR 2025)</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://ieeexplore.ieee.org/abstract/document/10802307" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects</h5>
            <p>We introduce a multi-robot TAMP algorithm that leverages feasibility prediction to address complex manipulation tasks. Our approach extends previous methods by enabling the handling of mesh-shaped objects and collaborative multi-robot settings, demonstrating significant improvements over baseline methods.</p>
            <span class="work-venue">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://ieeexplore.ieee.org/abstract/document/10341257" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning</h5>
            <p>We propose AGFP-Net, a multi-task neural network that predicts action feasibility and grasp type feasibility, significantly improving task and motion planning (TAMP) by reducing geometric planning time and solving more complex problems.</p>
            <span class="work-venue">2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments</h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block"><a href="https://smail8.github.io" target="_blank">Smail Ait Bouhsain</a>,</span>
                <span class="author-block"><a href="https://www.laas.fr/en/homepages/rachid/" target="_blank">Rachid Alami</a>,</span>
                <span class="author-block"><a href="https://www.laas.fr/fr/annuaire/29" target="_blank">Thierry Siméon</a></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">LAAS-CNRS<br>IEEE International Conference on Robotics and Automation (ICRA 2023)</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://ieeexplore.ieee.org/abstract/document/10161114" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="static/images/poster.png" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-photo-video"></i>
                      </span>
                      <span>Poster</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/smail8/action-grasp-feasibility-prediction" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://laas.hal.science/hal-03808885v2/document" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-hal"></i>
                      </span>
                      <span>HAL</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Teaser video-->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <iframe width="100%" height="500px" src="https://www.youtube.com/embed/lUs3DGHrSDE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          <h2 class="subtitle has-text-centered">
            Given the state of a 3D environment, a high-level action, and an object to manipulate, our method predicts the geometric feasibility of the action. These predictions are then used as a heuristic to guide task and motion planning, by prioritizing the most promising actions first. This approach significantly reduces the time spent on geometric planning, enabling the robot to solve manipulation tasks more efficiently in 3D environments.
          </h2>
        </div>
      </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                In Task and motion planning (TAMP), symbolic search is combined with continuous geometric planning. A task planner finds an action sequence while a motion planner checks its feasibility and plans the corresponding sequence of motions. However, due to the high combinatorial complexity of discrete search, the number of calls to the geometric planner can be very large. Previous works [1] [2] leverage learning methods to efficiently predict the feasibility of actions, much like humans do, on tabletop scenarios. This way, the time spent on motion planning can be greatly reduced. In this work, we generalize these methods to 3D environments, thus covering the whole workspace of the robot. We propose an efficient method for 3D scene representation, along with a deep neural network capable of predicting the probability of feasibility of an action. We develop a simple TAMP algorithm that integrates the trained classifier, and demonstrate the performance gain of using our approach on multiple problem domains. On complex problems, our method can reduce the time spent on geometric planning by up to 90%.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- Neural Network Image -->
    <section class="section hero is-small">
      <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Proposed Model</h2>
            <figure class="image">
              <img src="static/images/model.png" alt="Diagram of the proposed neural network AFPNet">
            </figure>
            <p class="subtitle">
              A visualization of the proposed neural network architecture used for action feasibility prediction.
            </p>
          </div>
        </div>
      </div>
    </section>
    <!-- End Neural Network Image -->

    <!-- Benchmarks Section -->
    <section class="section hero is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Benchmarks</h2>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <img src="static/images/reorder.png" alt="Reorder Benchmark">
              </figure>
                <p class="subtitle"><strong>Reorder problem:</strong> Objects initially placed on a two-shelf cupboard must be moved to another cupboard in a different order, testing the algorithm's ability to handle grasp choices and infeasible placements under shelves.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <img src="static/images/unpack.png" alt="Unpack Benchmark">
              </figure>
                <p class="subtitle"><strong>Unpack problem:</strong> Objects initially placed on a tray-like surface must be unpacked and ordered into a cupboard. The challenge lies in selecting feasible grasps due to the proximity of objects and the restricted goal placements under a shelf, which disallow top grasps.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <img src="static/images/swap.png" alt="Swap Benchmark">
              </figure>
              <p class="subtitle"><strong>Swap problem:</strong> A set of objects are initially placed either on the table or on higher support surfaces, and the goal is to swap their poses. The challenge arises from the fact that the goal poses of objects are already occupied, requiring the use of intermediary placements to achieve the desired configuration.</p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Benchmarks Section -->

    <!-- Results Section -->
    <section class="section hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Results</h2>
          <div class="columns is-centered">
            <!-- First image -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/times_2obj.png" alt="Results on 2-object problems">
              </figure>
              <p class="subtitle">Detailed planning time of our algorithm on the <strong>2-object</strong> version of the problems with and without using AFP-Net, averaged over 10 runs.</p>
            </div>
            <!-- Second image -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/times_5obj.png" alt="Results on 5-object problems">
              </figure>
              <p class="subtitle">Detailed planning time of our algorithm on the <strong>5-object</strong> version of the problems with and without using AFP-Net, averaged over 10 runs.</p>
            </div>
          </div>
          <!-- Add space between the first two figures and the last -->
          <div class="columns is-centered" style="margin-top: 2rem;"></div>
          <div class="columns is-centered">
            <!-- Third image -->
            <div class="column has-text-centered">
              <figure class="image">
                <img src="static/images/results.png" alt="Overall Results Comparison">
              </figure>
              <p class="subtitle">Comparison of the performance of the TAMP algorithm with and without using AFP-Net on the 5-object version of the three problem domains. Results are averaged over 10 runs.</p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Results Section -->

    <!-- Visualizations Section -->
    <section class="section hero is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Visualizations</h2>
          <div class="columns is-centered">
            <!-- First GIF -->
            <div class="column is-one-third has-text-centered">
              <figure class="image">
                <img src="static/images/reorder5.gif" alt="Visualization of the solution to the reorder task">
              </figure>
              <p class="subtitle">Execution of the reordering task with 5 objects.</p>
            </div>
            <!-- Second GIF -->
            <div class="column is-one-third has-text-centered">
              <figure class="image">
                <img src="static/images/unpack5.gif" alt="Visualization of the solution to the unpack task">
              </figure>
              <p class="subtitle">Execution of the unpacking task with 5 objects.</p>
            </div>
            <!-- Third GIF -->
            <div class="column is-one-third has-text-centered">
              <figure class="image">
                <img src="static/images/swap5.gif" alt="Visualization of the solution to the swapping task">
              </figure>
              <p class="subtitle">Execution of the swapping task with 5 objects.</p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Visualizations Section -->


    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code">
          <code>
            @inproceedings{ait2023learning,
              title={Learning to predict action feasibility for task and motion planning in 3d environments},
              author={Ait Bouhsain, Smail and Alami, Rachid and Simeon, Thierry},
              booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
              pages={3736--3742},
              year={2023},
              organization={IEEE}
            }
          </code>
        </pre>
      </div>
    </section>
    <!--End BibTex citation -->
  </main>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->
    
  <!-- Default Statcounter code for AFPNet (ICRA 2023)
  https://smail8.github.io/action-feasibility-prediction/ -->
  <script type="text/javascript">
    var sc_project=13197490; 
    var sc_invisible=1; 
    var sc_security="dc5a2c10"; 
  </script>
  <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript>
    <div class="statcounter">
      <a title="Web Analytics Made Easy - Statcounter" href="https://statcounter.com/" target="_blank">
        <img class="statcounter" src="https://c.statcounter.com/13197490/0/dc5a2c10/1/" alt="Web Analytics Made Easy - Statcounter" referrerPolicy="no-referrer-when-downgrade">
      </a>
    </div>
  </noscript>
  <!-- End of Statcounter Code -->
  <!-- End of Statcounter Code -->

</body>
</html>
